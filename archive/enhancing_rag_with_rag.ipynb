{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Coding Setup\n",
        "## Installation and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5x3LkpUztHNU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jPIRSGz4tHNV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/steffento/Dev/FMEA-RAG/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.runnables import  RunnablePassthrough\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "from neo4j import GraphDatabase\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from neo4j import  Driver\n",
        "import pandas as pd\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dataUploadAndMappingToGraph():\n",
        "    # Initialize Neo4j driver\n",
        "    driver = GraphDatabase.driver(\n",
        "        uri=os.environ[\"NEO4J_URI\"],\n",
        "        auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        "    )\n",
        "\n",
        "    def clear_database(tx):\n",
        "        \"\"\"Clear all nodes and relationships\"\"\"\n",
        "        tx.run(\"MATCH (n) DETACH DELETE n\")\n",
        "\n",
        "    def import_fmea_data(csv_file_path):\n",
        "        \"\"\"Import FMEA data from CSV into Neo4j\"\"\"\n",
        "        \n",
        "        # Read CSV\n",
        "        df = pd.read_csv(csv_file_path)\n",
        "        \n",
        "        # Track ID counters for each entity type\n",
        "        entity_counters = {\n",
        "            'product': 0,\n",
        "            'subsystem': 0,\n",
        "            'system_element': 0,\n",
        "            'function': 0,\n",
        "            'failure_mode': 0,\n",
        "            'failure_cause': 0,\n",
        "            'failure_effect': 0,\n",
        "            'measure': 0,\n",
        "\n",
        "        }\n",
        "        \n",
        "        # Track existing entities to avoid duplicates and ID conflicts\n",
        "        existing_entities = {\n",
        "            'product': {},\n",
        "            'subsystem': {},\n",
        "            'system_element': {},\n",
        "            'function': {},\n",
        "            'failure_mode': {},\n",
        "            'failure_cause': {},\n",
        "            'failure_effect': {},\n",
        "            'measure': {},\n",
        "\n",
        "        }\n",
        "        \n",
        "        severity_conflicts = []\n",
        "        \n",
        "        with driver.session() as session:\n",
        "            # Clear existing data\n",
        "            session.execute_write(clear_database)\n",
        "            print(\"Database cleared.\")\n",
        "            \n",
        "            for index, row in df.iterrows():\n",
        "                print(f\"Processing row {index + 1}/{len(df)}\")\n",
        "                \n",
        "                # Create/get Product\n",
        "                product_key = row['product']\n",
        "                if product_key not in existing_entities['product']:\n",
        "                    entity_counters['product'] += 1\n",
        "                    product_id = entity_counters['product']\n",
        "                    existing_entities['product'][product_key] = product_id\n",
        "                    session.execute_write(create_product_node, product_id, row['product'])\n",
        "                else:\n",
        "                    product_id = existing_entities['product'][product_key]\n",
        "                \n",
        "                # Create/get Subsystem\n",
        "                subsystem_key = f\"{product_key}_{row['subsystem']}\"\n",
        "                if subsystem_key not in existing_entities['subsystem']:\n",
        "                    entity_counters['subsystem'] += 1\n",
        "                    subsystem_id = entity_counters['subsystem']\n",
        "                    existing_entities['subsystem'][subsystem_key] = subsystem_id\n",
        "                    session.execute_write(create_subsystem_node, subsystem_id, row['subsystem'], product_id)\n",
        "                else:\n",
        "                    subsystem_id = existing_entities['subsystem'][subsystem_key]\n",
        "                \n",
        "                # Create/get SystemElement\n",
        "                system_element_key = f\"{subsystem_key}_{row['system_element']}\"\n",
        "                if system_element_key not in existing_entities['system_element']:\n",
        "                    entity_counters['system_element'] += 1\n",
        "                    system_element_id = entity_counters['system_element']\n",
        "                    existing_entities['system_element'][system_element_key] = system_element_id\n",
        "                    session.execute_write(create_system_element_node, system_element_id, row['system_element'], subsystem_id)\n",
        "                else:\n",
        "                    system_element_id = existing_entities['system_element'][system_element_key]\n",
        "                \n",
        "                # Create/get Function\n",
        "                function_key = f\"{system_element_key}_{row['function']}\"\n",
        "                if function_key not in existing_entities['function']:\n",
        "                    entity_counters['function'] += 1\n",
        "                    function_id = entity_counters['function']\n",
        "                    existing_entities['function'][function_key] = function_id\n",
        "                    session.execute_write(create_function_node, function_id, row['function'], system_element_id)\n",
        "                else:\n",
        "                    function_id = existing_entities['function'][function_key]\n",
        "                \n",
        "                # Create/get FailureMode\n",
        "                failure_mode_key = f\"{function_key}_{row['failure_mode']}\"\n",
        "                if failure_mode_key not in existing_entities['failure_mode']:\n",
        "                    entity_counters['failure_mode'] += 1\n",
        "                    failure_mode_id = entity_counters['failure_mode']\n",
        "                    existing_entities['failure_mode'][failure_mode_key] = failure_mode_id\n",
        "                    session.execute_write(create_failure_mode_node, failure_mode_id, row['failure_mode'], function_id)\n",
        "                else:\n",
        "                    failure_mode_id = existing_entities['failure_mode'][failure_mode_key]\n",
        "                \n",
        "                # Create/get FailureEffect with severity check\n",
        "                failure_effect_key = f\"{product_key}_{row['failure_effect']}\"\n",
        "                if failure_effect_key not in existing_entities['failure_effect']:\n",
        "                    entity_counters['failure_effect'] += 1\n",
        "                    failure_effect_id = entity_counters['failure_effect']\n",
        "                    existing_entities['failure_effect'][failure_effect_key] = failure_effect_id\n",
        "                    session.execute_write(create_failure_effect_node, failure_effect_id, row['failure_effect'], \n",
        "                                        row['severity_rating'], failure_mode_id)\n",
        "                else:\n",
        "                    failure_effect_id = existing_entities['failure_effect'][failure_effect_key]\n",
        "                    # Check for severity rating conflicts\n",
        "                    existing_severity = session.execute_read(get_failure_effect_severity, failure_effect_id)\n",
        "                    if existing_severity != row['severity_rating']:\n",
        "                        severity_conflicts.append({\n",
        "                            'failure_effect': row['failure_effect'],\n",
        "                            'existing_severity': existing_severity,\n",
        "                            'new_severity': row['severity_rating'],\n",
        "                            'row': index + 1\n",
        "                        })\n",
        "                        # Add both severity ratings as properties\n",
        "                        session.execute_write(add_severity_conflict, failure_effect_id, row['severity_rating'])\n",
        "                    else:\n",
        "                        # Create relationship if it doesn't exist\n",
        "                        session.execute_write(create_failure_mode_effect_relationship, failure_mode_id, failure_effect_id)\n",
        "                \n",
        "                # Create/get FailureCause\n",
        "                failure_cause_key = f\"{product_key}_{row['failure_cause']}\"\n",
        "                if failure_cause_key not in existing_entities['failure_cause']:\n",
        "                    entity_counters['failure_cause'] += 1\n",
        "                    failure_cause_id = entity_counters['failure_cause']\n",
        "                    existing_entities['failure_cause'][failure_cause_key] = failure_cause_id\n",
        "                    session.execute_write(create_failure_cause_node, failure_cause_id, row['failure_cause'], \n",
        "                                        row['occurrence_rating'], row['detection_rating'], failure_mode_id)\n",
        "                else:\n",
        "                    failure_cause_id = existing_entities['failure_cause'][failure_cause_key]\n",
        "                    # Create relationship if it doesn't exist\n",
        "                    session.execute_write(create_failure_mode_cause_relationship, failure_mode_id, failure_cause_id)\n",
        "                \n",
        "                # Create/get Measure (replaces both preventive and detective sections)\n",
        "                measure_key = f\"{product_key}_{row['measure_name']}\"\n",
        "                if measure_key not in existing_entities['measure']:\n",
        "                    entity_counters['measure'] += 1\n",
        "                    measure_id = entity_counters['measure']\n",
        "                    existing_entities['measure'][measure_key] = measure_id\n",
        "                    session.execute_write(create_measure_node, measure_id, row['measure_name'], \n",
        "                                        row['measure_description'], row['measure_type'], failure_cause_id)\n",
        "                else:\n",
        "                    measure_id = existing_entities['measure'][measure_key]\n",
        "                    session.execute_write(create_measure_relationship, failure_cause_id, measure_id, row['measure_type'])\n",
        "                \n",
        "        print(f\"\\nImport completed successfully!\")\n",
        "        print(f\"Created {entity_counters['product']} products\")\n",
        "        print(f\"Created {entity_counters['subsystem']} subsystems\")\n",
        "        print(f\"Created {entity_counters['system_element']} system elements\")\n",
        "        print(f\"Created {entity_counters['function']} functions\")\n",
        "        print(f\"Created {entity_counters['failure_mode']} failure modes\")\n",
        "        print(f\"Created {entity_counters['failure_cause']} failure causes\")\n",
        "        print(f\"Created {entity_counters['failure_effect']} failure effects\")\n",
        "        print(f\"Created {entity_counters['measure']} measures\")\n",
        "\n",
        "        \n",
        "        if severity_conflicts:\n",
        "            print(f\"\\nWARNING: Found {len(severity_conflicts)} severity rating conflicts:\")\n",
        "            for conflict in severity_conflicts:\n",
        "                print(f\"  Row {conflict['row']}: '{conflict['failure_effect']}' - \"\n",
        "                    f\"Existing: {conflict['existing_severity']}, New: {conflict['new_severity']}\")\n",
        "\n",
        "    # Node creation functions\n",
        "    def create_product_node(tx, product_id, name):\n",
        "        query = \"\"\"\n",
        "        MERGE (p:Product {id: $product_id, name: $name})\n",
        "        \"\"\"\n",
        "        tx.run(query, product_id=product_id, name=name)\n",
        "\n",
        "    def create_subsystem_node(tx, subsystem_id, name, product_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (s:Subsystem {id: $subsystem_id, name: $name})\n",
        "        MERGE (p:Product {id: $product_id})\n",
        "        MERGE (p)-[:hasSubsystem]->(s)\n",
        "        \"\"\"\n",
        "        tx.run(query, subsystem_id=subsystem_id, name=name, product_id=product_id)\n",
        "\n",
        "    def create_system_element_node(tx, system_element_id, name, subsystem_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (se:SystemElement {id: $system_element_id, name: $name})\n",
        "        MERGE (s:Subsystem {id: $subsystem_id})\n",
        "        MERGE (s)-[:hasSystemElement]->(se)\n",
        "        \"\"\"\n",
        "        tx.run(query, system_element_id=system_element_id, name=name, subsystem_id=subsystem_id)\n",
        "\n",
        "    def create_function_node(tx, function_id, name, system_element_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (f:Function {id: $function_id, name: $name})\n",
        "        MERGE (se:SystemElement {id: $system_element_id})\n",
        "        MERGE (se)-[:hasFunction]->(f)\n",
        "        \"\"\"\n",
        "        tx.run(query, function_id=function_id, name=name, system_element_id=system_element_id)\n",
        "\n",
        "    def create_failure_mode_node(tx, failure_mode_id, name, function_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (fm:FailureMode {id: $failure_mode_id, name: $name})\n",
        "        MERGE (f:Function {id: $function_id})\n",
        "        MERGE (f)-[:hasFailureMode]->(fm)\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_mode_id=failure_mode_id, name=name, function_id=function_id)\n",
        "\n",
        "    def create_failure_effect_node(tx, failure_effect_id, name, severity_rating, failure_mode_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (fe:FailureEffect {id: $failure_effect_id, name: $name, severity_rating: $severity_rating})\n",
        "        MERGE (fm:FailureMode {id: $failure_mode_id})\n",
        "        MERGE (fm)-[:resultsInFailureEffect]->(fe)\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_effect_id=failure_effect_id, name=name, \n",
        "            severity_rating=severity_rating, failure_mode_id=failure_mode_id)\n",
        "\n",
        "    def create_failure_cause_node(tx, failure_cause_id, name, occurrence_rating, detection_rating, failure_mode_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (fc:FailureCause {id: $failure_cause_id, name: $name, \n",
        "                            occurrence_rating: $occurrence_rating, \n",
        "                            detection_rating: $detection_rating})\n",
        "        MERGE (fm:FailureMode {id: $failure_mode_id})\n",
        "        MERGE (fm)-[:isDueToFailureCause]->(fc)\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_cause_id=failure_cause_id, name=name, \n",
        "            occurrence_rating=occurrence_rating, detection_rating=detection_rating, \n",
        "            failure_mode_id=failure_mode_id)\n",
        "\n",
        "    def create_measure_node(tx, measure_id, name, description, measure_type, failure_cause_id):\n",
        "        if measure_type == 'preventive':\n",
        "            relationship = 'isImprovedByPreventiveMeasure'\n",
        "        else:  # detective\n",
        "            relationship = 'isImprovedByDetectiveMeasure'\n",
        "        \n",
        "        query = f\"\"\"\n",
        "        MERGE (m:Measure {{id: $measure_id, name: $name, description: $description, type: $measure_type}})\n",
        "        MERGE (fc:FailureCause {{id: $failure_cause_id}})\n",
        "        MERGE (fc)-[:{relationship}]->(m)\n",
        "        \"\"\"\n",
        "        tx.run(query, measure_id=measure_id, name=name, description=description, \n",
        "            measure_type=measure_type, failure_cause_id=failure_cause_id)\n",
        "\n",
        "    # Relationship creation functions for existing nodes\n",
        "    def create_failure_mode_effect_relationship(tx, failure_mode_id, failure_effect_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (fm:FailureMode {id: $failure_mode_id})\n",
        "        MERGE (fe:FailureEffect {id: $failure_effect_id})\n",
        "        MERGE (fm)-[:resultsInFailureEffect]->(fe)\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_mode_id=failure_mode_id, failure_effect_id=failure_effect_id)\n",
        "\n",
        "    def create_failure_mode_cause_relationship(tx, failure_mode_id, failure_cause_id):\n",
        "        query = \"\"\"\n",
        "        MERGE (fm:FailureMode {id: $failure_mode_id})\n",
        "        MERGE (fc:FailureCause {id: $failure_cause_id})\n",
        "        MERGE (fm)-[:isDueToFailureCause]->(fc)\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_mode_id=failure_mode_id, failure_cause_id=failure_cause_id)\n",
        "\n",
        "    def create_measure_relationship(tx, failure_cause_id, measure_id, measure_type):\n",
        "        if measure_type == 'preventive':\n",
        "            relationship = 'isImprovedByPreventiveMeasure'\n",
        "        else:  # detective\n",
        "            relationship = 'isImprovedByDetectiveMeasure'\n",
        "        \n",
        "        query = f\"\"\"\n",
        "        MERGE (fc:FailureCause {{id: $failure_cause_id}})\n",
        "        MERGE (m:Measure {{id: $measure_id}})\n",
        "        MERGE (fc)-[:{relationship}]->(m)\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_cause_id=failure_cause_id, measure_id=measure_id)\n",
        "\n",
        "    # Utility functions\n",
        "    def get_failure_effect_severity(tx, failure_effect_id):\n",
        "        query = \"MATCH (fe:FailureEffect {id: $failure_effect_id}) RETURN fe.severity_rating\"\n",
        "        result = tx.run(query, failure_effect_id=failure_effect_id)\n",
        "        record = result.single()\n",
        "        return record[\"fe.severity_rating\"] if record else None\n",
        "\n",
        "    def add_severity_conflict(tx, failure_effect_id, new_severity):\n",
        "        query = \"\"\"\n",
        "        MATCH (fe:FailureEffect {id: $failure_effect_id})\n",
        "        SET fe.severity_rating_conflict = $new_severity\n",
        "        \"\"\"\n",
        "        tx.run(query, failure_effect_id=failure_effect_id, new_severity=new_severity)\n",
        "\n",
        "    csv_file_path = \"washing_machine2.csv\"  # Replace with your CSV file path\n",
        "    import_fmea_data(csv_file_path)\n",
        "    driver.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Vector Embedding for Graph Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_failure_mode_embeddings():\n",
        "    \"\"\"Generate rich contextual embeddings for FailureMode nodes\"\"\"\n",
        "    \n",
        "    driver = GraphDatabase.driver(\n",
        "        uri=os.environ[\"NEO4J_URI\"],\n",
        "        auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        "    )\n",
        "    \n",
        "    with driver.session() as session:\n",
        "        # Get all FailureMode nodes with their rich context\n",
        "        failure_modes = session.execute_read(get_failure_modes_with_context)\n",
        "        \n",
        "        print(f\"Found {len(failure_modes)} failure modes to process\")\n",
        "        \n",
        "        # Generate text chunks for each failure mode\n",
        "        for failure_mode in failure_modes:\n",
        "            text_chunk = generate_failure_mode_text_chunk(failure_mode)\n",
        "            \n",
        "            # Create VectorEmbedding node with the text chunk\n",
        "            session.execute_write(create_vector_embedding_node, \n",
        "                                failure_mode['failure_mode_id'], \n",
        "                                text_chunk)\n",
        "            \n",
        "            print(f\"Created embedding for: {failure_mode['failure_mode_name']}\")\n",
        "    \n",
        "    driver.close()\n",
        "    print(\"Embedding generation completed!\")\n",
        "\n",
        "def get_failure_modes_with_context(tx):\n",
        "    \"\"\"Retrieve all FailureMode nodes with their complete context\"\"\"\n",
        "    \n",
        "    query = \"\"\"\n",
        "    MATCH (p:Product)-[:hasSubsystem]->(s:Subsystem)-[:hasSystemElement]->(se:SystemElement)\n",
        "          -[:hasFunction]->(f:Function)-[:hasFailureMode]->(fm:FailureMode)\n",
        "    \n",
        "    OPTIONAL MATCH (fm)-[:isDueToFailureCause]->(fc:FailureCause)\n",
        "    OPTIONAL MATCH (fc)-[:isImprovedByPreventiveMeasure]->(pm:Measure {type: 'preventive'})\n",
        "    OPTIONAL MATCH (fc)-[:isImprovedByDetectiveMeasure]->(dm:Measure {type: 'detective'})\n",
        "    OPTIONAL MATCH (fm)-[:resultsInFailureEffect]->(fe:FailureEffect)\n",
        "    \n",
        "    WITH fm, p, s, se, f, fc, fe,\n",
        "         collect(DISTINCT pm.name) as preventive_measures_for_cause,\n",
        "         collect(DISTINCT dm.name) as detective_measures_for_cause\n",
        "    \n",
        "    WITH fm, p, s, se, f,\n",
        "         collect(DISTINCT {\n",
        "             name: fc.name,\n",
        "             occurrence_rating: fc.occurrence_rating,\n",
        "             detection_rating: fc.detection_rating,\n",
        "             preventive_measures: preventive_measures_for_cause,\n",
        "             detective_measures: detective_measures_for_cause\n",
        "         }) as causes_with_measures,\n",
        "         collect(DISTINCT {\n",
        "             name: fe.name,\n",
        "             severity_rating: fe.severity_rating\n",
        "         }) as effects_data\n",
        "    \n",
        "    RETURN fm.id as failure_mode_id,\n",
        "           fm.name as failure_mode_name,\n",
        "           p.name as product_name,\n",
        "           s.name as subsystem_name,\n",
        "           se.name as system_element_name,\n",
        "           f.name as function_name,\n",
        "           causes_with_measures,\n",
        "           effects_data\n",
        "    \"\"\"\n",
        "    \n",
        "    result = tx.run(query)\n",
        "    \n",
        "    # Transform results with proper cause-measure relationships\n",
        "    transformed_results = []\n",
        "    for record in result:\n",
        "        data = record.data()\n",
        "        \n",
        "        # Clean up causes data - filter out null entries and format properly\n",
        "        causes = []\n",
        "        for cause_data in data['causes_with_measures']:\n",
        "            if cause_data['name'] is not None:  # Only include actual causes\n",
        "                formatted_cause = {\n",
        "                    'cause_name': cause_data['name'],\n",
        "                    'occurrence_rating': cause_data['occurrence_rating'],\n",
        "                    'detection_rating': cause_data['detection_rating'],\n",
        "                    'preventive_measures': [m for m in cause_data['preventive_measures'] if m is not None],\n",
        "                    'detective_measures': [m for m in cause_data['detective_measures'] if m is not None]\n",
        "                }\n",
        "                causes.append(formatted_cause)\n",
        "        \n",
        "        # Clean up effects data - filter out null entries\n",
        "        effects = []\n",
        "        for effect_data in data['effects_data']:\n",
        "            if effect_data['name'] is not None:  # Only include actual effects\n",
        "                formatted_effect = {\n",
        "                    'effect_name': effect_data['name'],\n",
        "                    'severity_rating': effect_data['severity_rating']\n",
        "                }\n",
        "                effects.append(formatted_effect)\n",
        "        \n",
        "        # Create the final data structure\n",
        "        transformed_data = {\n",
        "            'failure_mode_id': data['failure_mode_id'],\n",
        "            'failure_mode_name': data['failure_mode_name'],\n",
        "            'product_name': data['product_name'],\n",
        "            'subsystem_name': data['subsystem_name'],\n",
        "            'system_element_name': data['system_element_name'],\n",
        "            'function_name': data['function_name'],\n",
        "            'causes': causes,\n",
        "            'effects': effects\n",
        "        }\n",
        "        \n",
        "        transformed_results.append(transformed_data)\n",
        "    \n",
        "    return transformed_results\n",
        "\n",
        "def generate_failure_mode_text_chunk(failure_mode_data):\n",
        "    \"\"\"Generate rich contextual text chunk for a FailureMode\"\"\"\n",
        "    \n",
        "    # Extract basic information\n",
        "    fm_name = failure_mode_data['failure_mode_name']\n",
        "    product = failure_mode_data['product_name']\n",
        "    subsystem = failure_mode_data['subsystem_name']\n",
        "    system_element = failure_mode_data['system_element_name']\n",
        "    function = failure_mode_data['function_name']\n",
        "    causes = failure_mode_data['causes']\n",
        "    effects = failure_mode_data['effects']\n",
        "    \n",
        "    # Build the text chunk\n",
        "    text_parts = []\n",
        "    \n",
        "    # System hierarchy context\n",
        "    text_parts.append(f\"The failure mode '{fm_name}' occurs in the '{system_element}' component, \"\n",
        "                     f\"which is part of the '{subsystem}' subsystem in the '{product}' system.\")\n",
        "    \n",
        "    # Function context\n",
        "    text_parts.append(f\"This failure affects the '{function}' function of the '{system_element}'.\")\n",
        "    \n",
        "    # Failure causes context\n",
        "    if causes and any(cause['cause_name'] for cause in causes if cause['cause_name']):\n",
        "        text_parts.append(f\"The failure mode '{fm_name}' can be caused by the following failure causes: \")\n",
        "        for cause in causes:\n",
        "            if cause['cause_name']:\n",
        "                cause_text = f\" Failure cause '{cause['cause_name']}'\"\n",
        "                if cause['occurrence_rating']:\n",
        "                    cause_text += f\" with an occurrence rating of {cause['occurrence_rating']}\"\n",
        "                if cause['detection_rating']:\n",
        "                    cause_text += f\" and a detection rating of {cause['detection_rating']}.\"\n",
        "                elif cause['occurrence_rating']:\n",
        "                    cause_text += \")\"\n",
        "                \n",
        "                # Add preventive measures\n",
        "                preventive_measures = [m for m in cause['preventive_measures'] if m]\n",
        "                if preventive_measures:\n",
        "                    cause_text += f\" Preventive measures for the failure cause '{cause['cause_name']}' are: '{', '.join(preventive_measures)}'.\"\n",
        "                \n",
        "                # Add detective measures\n",
        "                detective_measures = [m for m in cause['detective_measures'] if m]\n",
        "                if detective_measures:\n",
        "                    cause_text += f\" Detective measures for the failure cause '{cause['cause_name']}' are: '{', '.join(detective_measures)}.'\"\n",
        "                \n",
        "                text_parts.append(cause_text)\n",
        "    \n",
        "    # Failure effects context\n",
        "    if effects and any(effect['effect_name'] for effect in effects if effect['effect_name']):\n",
        "        text_parts.append(f\" The failure mode '{fm_name}' results in the following failure effects:\")\n",
        "        for effect in effects:\n",
        "            if effect['effect_name']:\n",
        "                effect_text = f\" Failure effect '{effect['effect_name']}'\"\n",
        "                if effect['severity_rating']:\n",
        "                    effect_text += f\" with a severity rating of {effect['severity_rating']}.\"\n",
        "                text_parts.append(effect_text)\n",
        "    \n",
        "    # Join all parts with proper spacing\n",
        "    full_text = \" \".join(text_parts)\n",
        "    \n",
        "    return full_text\n",
        "\n",
        "def create_vector_embedding_node(tx, failure_mode_id, text_chunk):\n",
        "    \"\"\"Create a VectorEmbedding node linked to the FailureMode\"\"\"\n",
        "    \n",
        "    query = \"\"\"\n",
        "    MATCH (fm:FailureMode {id: $failure_mode_id})\n",
        "    MERGE (ve:VectorEmbedding {\n",
        "        failure_mode_id: $failure_mode_id,\n",
        "        text_chunk: $text_chunk\n",
        "    })\n",
        "    MERGE (fm)-[:HAS_EMBEDDING]->(ve)\n",
        "    \"\"\"\n",
        "    \n",
        "    tx.run(query, failure_mode_id=failure_mode_id, text_chunk=text_chunk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Vector Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vector_index():\n",
        "    \"\"\"Create the Neo4j vector index - run this ONLY after new data is added\"\"\"\n",
        "    \n",
        "    # Initialize embeddings\n",
        "    # This is where I could set more parameters for the embeddings like: model='mxbai-embed-large' validate_model_on_init=False base_url=None client_kwargs={} async_client_kwargs={} sync_client_kwargs={} mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None keep_alive=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None\n",
        "    embeddings = OllamaEmbeddings(\n",
        "        model=\"mxbai-embed-large\",\n",
        "        # Add other params as needed for production\n",
        "    )\n",
        "    \n",
        "    # Create the actual vector index in Neo4j\n",
        "    # This creates the index structure in the database\n",
        "    vector_index = Neo4jVector.from_existing_graph(\n",
        "        embeddings,\n",
        "        search_type=\"hybrid\",\n",
        "        node_label=\"VectorEmbedding\", \n",
        "        text_node_properties=[\"text_chunk\"],\n",
        "        embedding_node_property=\"embedding\",\n",
        "        index_name=\"failure_mode_context_index\",\n",
        "        keyword_index_name=\"failure_mode_keyword_index\"\n",
        "    )\n",
        "    \n",
        "    print(\"Vector index 'failure_mode_context_index' created successfully!\")\n",
        "    print(\"Vector index 'failure_mode_keyword_index' created successfully!\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def get_retriever(amountResults):\n",
        "    \n",
        "    # Initialize the same embeddings configuration\n",
        "    embeddings = OllamaEmbeddings(\n",
        "        model=\"mxbai-embed-large\",\n",
        "    )\n",
        "    \n",
        "    # Connect to existing index (doesn't recreate it)\n",
        "    vector_store = Neo4jVector.from_existing_index(\n",
        "        embeddings,\n",
        "        search_type=\"hybrid\",\n",
        "        index_name=\"failure_mode_context_index\",\n",
        "        keyword_index_name=\"failure_mode_keyword_index\"\n",
        "    )\n",
        "    \n",
        "    return vector_store.as_retriever(search_kwargs={\"k\": amountResults})\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creation of Full text index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_fmea_fulltext_indexes():\n",
        "    \"\"\"Create fulltext indexes for all FMEA entity types.\"\"\"\n",
        "    \n",
        "    driver = GraphDatabase.driver(\n",
        "        uri=os.environ[\"NEO4J_URI\"],\n",
        "        auth=(os.environ[\"NEO4J_USERNAME\"], os.environ[\"NEO4J_PASSWORD\"])\n",
        "    )\n",
        "    \n",
        "    def create_fulltext_index(tx):\n",
        "        # Single comprehensive index for all FMEA entities\n",
        "        query = '''\n",
        "        CREATE FULLTEXT INDEX `fulltext_entity_id` IF NOT EXISTS\n",
        "        FOR (n:SystemElement|Subsystem|FailureMode|Function|FailureCause|FailureEffect|Measure|Product) \n",
        "        ON EACH [n.name]\n",
        "        '''\n",
        "        tx.run(query)\n",
        "    \n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            session.execute_write(create_fulltext_index)\n",
        "            print(\"FMEA fulltext index created successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Index creation failed or already exists: {e}\")\n",
        "    finally:\n",
        "        driver.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG\n",
        "## Component 1: Entity Extraction\n",
        "Purpose: Identifies character names from user questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yCMz_sRtHNW",
        "outputId": "f533f279-9a2b-48d6-830b-28d04c43550b"
      },
      "outputs": [],
      "source": [
        "def extract_fmea_entities(question: str, llm, debug: bool) -> dict:\n",
        "    fmea_entity_prompt_old = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \n",
        "         \"You are an FMEA entity extraction specialist. Extract relevant entities from user questions \"\n",
        "         \"to enable precise knowledge graph queries. Map entities to these exact types: \"\n",
        "         \"FailureCause, FailureEffect, FailureMode, Function, Measure, Product, Subsystem, SystemElement.\"\n",
        "         \"\\n\\nPRODUCT ENTITY SPECIAL RULES:\"\n",
        "         \"\\n- Extract Product entities ONLY when user explicitly requests system structure generation\"\n",
        "         \"\\n- Generation keywords: 'create', 'develop', 'build', 'generate', 'design', 'structure'\"\n",
        "         \"\\n- For Product entities, provide 2 linguistic variations: synonyms and abstraction levels\"\n",
        "         \"\\n- Example: 'Electric Vehicle' → variations: ['EV', 'Electric Car'] (synonym + abstraction)\"\n",
        "         \"\\n- Analytical questions about existing systems should have Product: []\"\n",
        "         \"\\n\\nENTITY MAPPING GUIDELINES:\"\n",
        "         \"\\n- SystemElement: Physical components (motor, pump, brake, sensor, valve)\"\n",
        "         \"\\n- Subsystem: Groups of components (brake system, hydraulic system, control system)\"\n",
        "         \"\\n- Product: Complete systems or end products\"\n",
        "         \"\\n- Function: What something does (braking, pumping, cooling, monitoring)\"\n",
        "         \"\\n- FailureMode: Ways things can fail (overheating, leakage, fracture, jamming)\"\n",
        "         \"\\n- FailureCause: Root causes (wear, corrosion, overload, contamination)\"\n",
        "         \"\\n- FailureEffect: Consequences (loss of function, safety risk, performance degradation)\"\n",
        "         \"\\n- Measure: Preventive/corrective actions (inspection, maintenance, design change)\"\n",
        "         \"\\n\\nSYNONYM HANDLING:\"\n",
        "         \"\\n- Technical variants: breakdown→failure, component→SystemElement\"\n",
        "         \"\\n- Context-aware: 'failure' alone → look for context clues\"\n",
        "         \"\\n\\nFORMAT REQUIREMENTS:\"\n",
        "         \"\\n- Return ONLY valid JSON, no explanations or additional text\"\n",
        "         \"\\n- Use empty arrays [] for entity types with no matches\"\n",
        "         \"\\n- All entity type keys must be present in output\"\n",
        "         \"\\n- Entity names should be clean and standardized\"\n",
        "         \"\\n\\nEXAMPLE OUTPUTS:\"\n",
        "         \"\\n- Question: 'What failures occur in brake system?'\"\n",
        "         \"\\n  Response: {\\\"FailureCause\\\": [], \\\"FailureEffect\\\": [], \\\"FailureMode\\\": [], \\\"Function\\\": [], \\\"Measure\\\": [], \\\"Product\\\": [], \\\"Subsystem\\\": [\\\"Brake System\\\"], \\\"SystemElement\\\": []}\"\n",
        "         \"\\n- Question: 'What measures prevent motor overheating?'\"\n",
        "         \"\\n  Response: {\\\"FailureCause\\\": [], \\\"FailureEffect\\\": [], \\\"FailureMode\\\": [\\\"Overheating\\\"], \\\"Function\\\": [], \\\"Measure\\\": [], \\\"Product\\\": [], \\\"Subsystem\\\": [], \\\"SystemElement\\\": [\\\"Motor\\\"]}\"\n",
        "         \"\\n- Question: 'Create FMEA structure for electric vehicle'\"\n",
        "         \"\\n  Response: {\\\"FailureCause\\\": [], \\\"FailureEffect\\\": [], \\\"FailureMode\\\": [], \\\"Function\\\": [], \\\"Measure\\\": [], \\\"Product\\\": [\\\"Electric Vehicle\\\", \\\"EV\\\", \\\"Electric Car\\\"], \\\"Subsystem\\\": [], \\\"SystemElement\\\": []}\"\n",
        "        ),\n",
        "        (\"human\", \n",
        "         \"Extract FMEA entities from this question: {question}\"\n",
        "         \"\\nReturn only the JSON with all entity types, using empty arrays for unmatched types.\"\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    fmea_entity_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \n",
        "         \"You are an FMEA entity extraction specialist. Extract relevant entities from user questions \"\n",
        "         \"to enable precise knowledge graph queries. Map entities to these exact types: \"\n",
        "         \"FailureCause, FailureEffect, FailureMode, Function, Measure, Product, Subsystem, SystemElement. \"\n",
        "         \"\\n\\nPRODUCT ENTITY SPECIAL RULES:\"\n",
        "         \"\\n- When user explicitly requests system structure generation ONLY the Product entity should be extracted.\"\n",
        "         \"\\n- Generation keywords: 'create', 'develop', 'build', 'generate', 'design', 'structure'\"\n",
        "         \"\\n- For Product entities, provide 2 additional linguistic variations: synonyms and abstraction levels\"\n",
        "         \"\\n- Example: ['Electric Vehicle', 'EV', 'Electric Car'] (extracted entity, synonym, abstraction)\"\n",
        "         \"\\n\\nENTITY MAPPING GUIDELINES:\"\n",
        "         \"\\n- SystemElement: Physical components (motor, pump, brake, sensor, valve)\"\n",
        "         \"\\n- Subsystem: Groups of components (brake system, hydraulic system, control system)\"\n",
        "         \"\\n- Product: Complete systems or end products\"\n",
        "         \"\\n- Function: What something does (braking, pumping, cooling, monitoring)\"\n",
        "         \"\\n- FailureMode: Ways things can fail (overheating, leakage, fracture, jamming)\"\n",
        "         \"\\n- FailureCause: Root causes (wear, corrosion, overload, contamination)\" \n",
        "         \"\\n- FailureEffect: Consequences (loss of function, safety risk, performance degradation)\"\n",
        "         \"\\n- Measure: Preventive/corrective actions (inspection, maintenance, design change)\"\n",
        "         \"\\n\\nSYNONYM HANDLING:\"\n",
        "         \"\\n- Technical variants: breakdown→failure, component→SystemElement\"\n",
        "         \"\\n- Context-aware: 'failure' alone → look for context clues\"\n",
        "         \"\\n\\nFORMAT REQUIREMENTS:\"\n",
        "         \"\\n- Return ONLY valid JSON, no explanations or additional text\"\n",
        "         \"\\n- Use empty arrays [] for entity types with no matches\"\n",
        "         \"\\n- All entity type keys must be present in output\"\n",
        "         \"\\n- Entity names should be clean and standardized\"\n",
        "         \"\\n- Entity types must match the defined categories exactly and are the key of the output, following a list with extracted entities.\"\n",
        "        ),\n",
        "        (\"human\", \n",
        "         \"Extract FMEA entities from this question: {question}\"\n",
        "         \"\\nReturn only the JSON with all entity types, using empty arrays for unmatched types.\"\n",
        "        )\n",
        "    ])\n",
        "    \n",
        "    \n",
        "    try:\n",
        "        response = llm.invoke(fmea_entity_prompt.format(question=question))\n",
        "        print(response)\n",
        "        json_text = response.content.strip()\n",
        "        if debug:\n",
        "            print(f\"Raw LLM response: '{json_text}'\") \n",
        "            print(f\"Response length: {len(json_text)}\")\n",
        "        \n",
        "        # Try to clean common issues\n",
        "        json_text = json_text.replace('```json', '').replace('```', '')\n",
        "        json_text = json_text.strip()\n",
        "        \n",
        "        entities = json.loads(json_text)\n",
        "        if debug:\n",
        "            print(\"Entities: \", entities)\n",
        "            print(\"Successful entity extraction\")\n",
        "        return entities\n",
        "    \n",
        "    except json.JSONDecodeError as e:\n",
        "        if debug:\n",
        "            print(f\"JSON parsing failed: {e}\")\n",
        "            print(f\"Problematic text: '{json_text}'\") \n",
        "        # Return fallback\n",
        "        return {\n",
        "            \"FailureCause\": [],\n",
        "            \"FailureEffect\": [],\n",
        "            \"FailureMode\": [],\n",
        "            \"Function\": [],\n",
        "            \"Measure\": [],\n",
        "            \"Product\": [],\n",
        "            \"Subsystem\": [],\n",
        "            \"SystemElement\": []\n",
        "        }\n",
        "    except Exception as e:\n",
        "        if debug:\n",
        "            print(f\"General entity extraction failed: {e}\")\n",
        "        return {\n",
        "            \"FailureCause\": [],\n",
        "            \"FailureEffect\": [],\n",
        "            \"FailureMode\": [],\n",
        "            \"Function\": [],\n",
        "            \"Measure\": [],\n",
        "            \"Product\": [],\n",
        "            \"Subsystem\": [],\n",
        "            \"SystemElement\": []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 3: Graph neighborhood retrievel\n",
        "Purpose: Find character relationships using graph traversal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6fOJRPntHNX",
        "outputId": "a99ffca0-2d4d-4374-8519-c6e37c395f1f"
      },
      "outputs": [],
      "source": [
        "def generate_cypher_query(question: str, entities: dict, llm) -> str:\n",
        "    \"\"\"Generate executable Cypher query from extracted FMEA entities.\"\"\"\n",
        "    \n",
        "    cypher_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\n",
        "            \"system\", \n",
        "            \"Generate valid Cypher queries for FMEA knowledge graphs. Output ONLY the query.\\n\\n\"\n",
        "            \"EXACT SCHEMA:\\n\"\n",
        "            \"Nodes: Product, Subsystem, SystemElement, Function, FailureMode, FailureCause, FailureEffect, Measure\\n\"\n",
        "            \"Relationships: hasSubsystem, hasSystemElement, hasFunction, hasFailureMode, isDueToFailureCause, resultsInFailureEffect, isImprovedByPreventiveMeasure, isImprovedByDetectiveMeasure\\n\"\n",
        "            \"Properties: name, description, severity_rating, occurrence_rating, detection_rating, id, type, failure_mode_id, text_chunk\\n\\n\"\n",
        "            \"MANDATORY RULES:\\n\"\n",
        "            \"1. Use ONLY relationships from schema above\\n\"\n",
        "            \"2. Use ONLY node labels from schema above\\n\" \n",
        "            \"3. Use ONLY properties from schema above\\n\"\n",
        "            \"4. ALWAYS exclude VectorEmbedding: WHERE NOT 'VectorEmbedding' IN labels(n)\\n\"\n",
        "            \"5. Use fuzzy matching: WHERE n.name CONTAINS 'EntityName'\\n\"\n",
        "            \"6. Include ratings ONLY when question contains: rating, severity, occurrence, detection, S, O, D\\n\"\n",
        "            \"7. Always LIMIT 20\\n\"\n",
        "            \"8. Return as: node.property_name\\n\\n\"\n",
        "            \"EXAMPLES:\\n\"\n",
        "            \"Entities: {'SystemElement': ['Motor']}\\n\"\n",
        "            \"Query: MATCH (se:SystemElement) WHERE se.name CONTAINS 'Motor' AND NOT 'VectorEmbedding' IN labels(se) OPTIONAL MATCH (se)-[:hasFunction]->(f:Function)-[:hasFailureMode]->(fm:FailureMode) RETURN se.name, f.name, fm.name, fm.description LIMIT 20\\n\\n\"\n",
        "            \"OUTPUT: Return ONLY the Cypher query.\"\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Question: {question}\\nEntities: {entities}\"\n",
        "        )\n",
        "    ])\n",
        "    \n",
        "    response = llm.invoke(cypher_prompt.format(question=question, entities=str(entities)))\n",
        "    return response.content.strip()\n",
        "\n",
        "\n",
        "def generate_fallback_query(entities: dict) -> str:\n",
        "    \"\"\"Generate simple fallback query retrieving all connected nodes.\"\"\"\n",
        "    print(entities)\n",
        "    for entity_type, entity_list in entities.items():\n",
        "        if entity_list:\n",
        "            for entity in entity_list:\n",
        "                return f\"\"\"\n",
        "                MATCH (n:{entity_type})\n",
        "                WHERE toLower(n.name) CONTAINS toLower({entity})\n",
        "                OPTIONAL MATCH (n)-[r]-(connected)\n",
        "                RETURN n.name as entity_name,\n",
        "                    properties(n) as entity_properties,\n",
        "                    type(r) as relationship_type,\n",
        "                    connected.name as connected_name,\n",
        "                    properties(connected) as connected_properties\n",
        "                LIMIT 20\n",
        "                \"\"\"\n",
        "    \n",
        "    return \"MATCH (n) WHERE NOT 'VectorEmbedding' IN labels(n) RETURN n.name, labels(n) LIMIT 10\"\n",
        "\n",
        "def execute_fmea_query(question: str, entities: dict, llm, graph, debug: bool) -> dict:\n",
        "    \"\"\"Execute Cypher query with fallback on failure.\"\"\"\n",
        "    try:\n",
        "        cypher_query = generate_cypher_query(question, entities, llm)\n",
        "        print(\"Cypher Query: \", cypher_query)\n",
        "        raw_results = graph.query(cypher_query)\n",
        "        if debug:\n",
        "            print(cypher_query)\n",
        "            print(raw_results)\n",
        "        \n",
        "        return {\n",
        "            \"query\": cypher_query,\n",
        "            \"results_count\": len(raw_results),\n",
        "            \"fmea_data\": [dict(record) for record in raw_results]\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"exception fallback\")\n",
        "        fallback_query = generate_fallback_query(entities)\n",
        "        \n",
        "        try:\n",
        "            fallback_results = graph.query(fallback_query)\n",
        "            if debug:\n",
        "                print(\"Primary query failed, executed fallback query.\")\n",
        "                print(fallback_query)\n",
        "                print(fallback_results)\n",
        "            return {\n",
        "                \"query\": fallback_query, \n",
        "                \"results_count\": len(fallback_results),\n",
        "                \"fmea_data\": [dict(record) for record in fallback_results],\n",
        "                \"fallback_used\": True,\n",
        "                \"original_error\": str(e)\n",
        "            }\n",
        "        except Exception as fallback_error:\n",
        "            print(\"fallback, fallback\")\n",
        "            return {\n",
        "                \"error\": f\"Primary: {str(e)}, Fallback: {str(fallback_error)}\",\n",
        "                \"results_count\": 0,\n",
        "                \"fmea_data\": []\n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 4: hybrid retrieval Combination\n",
        "Purpose: Combines Graph and vector search results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCTMp3prtHNX"
      },
      "outputs": [],
      "source": [
        "def comprehensive_got_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Combines multiple retrieval strategies for comprehensive information gathering.\n",
        "    \n",
        "    This hybrid approach leverages:\n",
        "    1. Graph traversal for explicit relationship data\n",
        "    2. Vector search for semantic similarity and relationship descriptions\n",
        "    3. Character profile information for context\n",
        "    \n",
        "    Why hybrid retrieval is powerful:\n",
        "    - Graph data provides factual, structured relationships\n",
        "    - Vector data provides rich, descriptive context\n",
        "    - Combination gives both precision and comprehensiveness\n",
        "    \n",
        "    For FMEA adaptation:\n",
        "    - Graph data would provide explicit failure mode linkages\n",
        "    - Vector search would find semantically similar failure patterns\n",
        "    - Could combine quantitative risk data with qualitative descriptions\n",
        "    \"\"\"\n",
        "    # Get structured relationship data from graph traversal\n",
        "    graph_data = get_character_relationships(question)\n",
        "    \n",
        "    # Get semantic relationship information from vector search\n",
        "    # Using both character and relationship retrievers for comprehensive coverage\n",
        "\n",
        "    relationship_vector_data = relationship_retriever.invoke(question)\n",
        "    \n",
        "    # Combine character profiles and relationship descriptions\n",
        "\n",
        "    relationship_descriptions = [doc.page_content for doc in relationship_vector_data]\n",
        "    \n",
        "    # Structure the combined data for the language model\n",
        "    final_context = f\"\"\"\n",
        "=== GRAPH RELATIONSHIP DATA ===\n",
        "{graph_data}\n",
        "\n",
        "=== RELATIONSHIP DESCRIPTIONS ===  \n",
        "{chr(10).join(relationship_descriptions)}\n",
        "\"\"\"\n",
        "    \n",
        "    print(\"Retrieved context length:\", len(final_context))\n",
        "    return final_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 5: Respones Generation Chain\n",
        "Purpose: Generates natural language answers using retrieved information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dzb2jcittHNY"
      },
      "outputs": [],
      "source": [
        "# Create specialized prompt template for Game of Thrones questions\n",
        "got_rag_template = \"\"\"You are a Game of Thrones expert assistant. Answer the question based only on the provided context information.\n",
        "\n",
        "Context Information:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Instructions:\n",
        "- Use only the information provided in the context\n",
        "- Be specific about book numbers when relationships are mentioned\n",
        "- Include interaction strengths when relevant\n",
        "- If the context doesn't contain enough information, say so clearly\n",
        "- Provide a natural, conversational response\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "got_prompt = ChatPromptTemplate.from_template(got_rag_template)\n",
        "\n",
        "# Create the complete RAG chain\n",
        "got_rag_chain = (\n",
        "    {\n",
        "        \"context\": comprehensive_got_retriever,\n",
        "        \"question\": RunnablePassthrough(),\n",
        "    }\n",
        "    | got_prompt\n",
        "    | chat_llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Component 6: Enhanced Question Answering Interface\n",
        "Purpose: provides user Friendly interface with detailed response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dtU0iMNgtHNY",
        "outputId": "bf3cf94c-f030-41b4-fb3b-356c5bff98f5"
      },
      "outputs": [],
      "source": [
        "def test_entity_extraction():\n",
        "    \"\"\"\n",
        "    Test function to verify entity extraction is working correctly.\n",
        "    This kind of component testing is essential for complex AI systems.\n",
        "    \"\"\"\n",
        "    print(\"Testing entity extraction component...\")\n",
        "    \n",
        "    test_questions = [\n",
        "        \"Who is Jon Snow?\",\n",
        "        \"Tell me about Jon Snow and Tyrion Lannister\",\n",
        "        \"What about the Stark family?\",\n",
        "        \"Who does Jon Snow interact with and how strong are those relationships?\"\n",
        "    ]\n",
        "    \n",
        "    for question in test_questions:\n",
        "        print(f\"\\nTesting: '{question}'\")\n",
        "        try:\n",
        "            entities = extract_got_entities(question)\n",
        "            print(f\"✅ Success: {entities}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed: {e}\")\n",
        "\n",
        "def ask_got_question(question: str, show_context: bool = False):\n",
        "    \"\"\"\n",
        "    User-friendly interface for asking Game of Thrones questions.\n",
        "    \n",
        "    This wrapper function:\n",
        "    - Executes the full RAG pipeline\n",
        "    - Optionally shows the retrieved context for transparency\n",
        "    - Provides clear formatting for responses\n",
        "    \n",
        "    For FMEA adaptation:\n",
        "    - Would include risk level indicators in responses\n",
        "    - Could show confidence scores for failure predictions\n",
        "    - Might include regulatory compliance information\n",
        "    \"\"\"\n",
        "    print(f\"Question: {question}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    if show_context:\n",
        "        context = comprehensive_got_retriever(question)\n",
        "        print(\"RETRIEVED CONTEXT:\")\n",
        "        print(context)\n",
        "        print(\"=\" * 50)\n",
        "    \n",
        "    answer = got_rag_chain.invoke(question)\n",
        "    print(\"ANSWER:\")\n",
        "    print(answer)\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing LLM Invoke Directly ===\n",
            "✅ Simple invoke works: content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 9, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4f3d32ad4e', 'id': 'chatcmpl-CBdyYHXeCvO3y5jpAh8rqoVRsPsnx', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--75bb50ea-f8b9-408d-bfb5-f4115c4d0385-0' usage_metadata={'input_tokens': 9, 'output_tokens': 10, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "\n",
            "=== Testing with Prompt Template ===\n",
            "Formatted prompt: System: You are helpful\n",
            "Human: Say hello\n",
            "✅ Prompt template works: content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 17, 'total_tokens': 27, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4f3d32ad4e', 'id': 'chatcmpl-CBdyZVt5sY3eit5mghgiI4jQeU2OV', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--96937866-6160-43b4-977e-eda7ad7fbdba-0' usage_metadata={'input_tokens': 17, 'output_tokens': 10, 'total_tokens': 27, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "=== Testing Your FMEA Prompt ===\n",
            "Formatted prompt length: 134\n",
            "✅ FMEA prompt works: content='```json\\n{\\n  \"FailureCause\": \"overheating\",\\n  \"SystemElement\": \"motor\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 35, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4f3d32ad4e', 'id': 'chatcmpl-CBdya3KKC8M799Z78I8Ptn55jYN01', 'service_tier': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run--84d95282-6683-44c6-a34d-b5a2e8e2112c-0' usage_metadata={'input_tokens': 35, 'output_tokens': 25, 'total_tokens': 60, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exception fallback\n",
            "{'FailureCause': [], 'FailureEffect': [], 'FailureMode': ['Excessive vibration'], 'Function': [], 'Measure': [], 'Product': [], 'Subsystem': [], 'SystemElement': []}\n",
            "fallback, fallback\n"
          ]
        }
      ],
      "source": [
        "# Variable definitions\n",
        "dataUploadRequired = False # active if new data should be uploaded to knowledge graph\n",
        "\n",
        "# Setup\n",
        "graph = Neo4jGraph()\n",
        "\n",
        "# For entity extraction (keep the functions model)\n",
        "entity_llm = ChatOllama(model=\"gemma3:4b\", temperature=0 \n",
        ")\n",
        "\n",
        "# For conversational responses (new standard chat model)\n",
        "chat_llm = ChatOllama(model=\"gemma3:4b\", temperature=0.3)\n",
        "\n",
        "azure_llm = AzureChatOpenAI(\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    azure_deployment=\"gpt-4.1-mini\",\n",
        "    model_name=\"gpt-4.1-mini\"\n",
        ")\n",
        "\n",
        "if dataUploadRequired:\n",
        "    dataUploadAndMappingToGraph()\n",
        "    create_failure_mode_embeddings()\n",
        "    create_vector_index()\n",
        "    create_fmea_fulltext_indexes()\n",
        "\n",
        "# initiate retriever for vector query\n",
        "retriever = get_retriever(amountResults=10)\n",
        "\n",
        "question = \"What are the failure causes for the failure mode Excessive vibration?\"\n",
        "\n",
        " # Extract entities using your existing function\n",
        "#entities = extract_fmea_entities(question, azure_llm, debug=False)\n",
        "\n",
        "entities = {'FailureCause': [], 'FailureEffect': [], 'FailureMode': ['Excessive vibration'], 'Function': [], 'Measure': [], 'Product': [], 'Subsystem': [], 'SystemElement': []}\n",
        "\n",
        "# Execute graph query\n",
        "graph_results = execute_fmea_query(question, entities, azure_llm, graph, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Direct character relationship question\n",
        "ask_got_question(\n",
        "        \"Who talks Tyrion Lannister the most to?\",\n",
        "        show_context=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e37edd9789a4d57a7be401628e7ff7f": {
          "model_module": "yfiles-jupyter-graphs",
          "model_module_version": "^1.6.1",
          "model_name": "GraphModel",
          "state": {
            "_context_pane_mapping": [
              {
                "id": "Neighborhood",
                "title": "Neighborhood"
              },
              {
                "id": "Data",
                "title": "Data"
              },
              {
                "id": "Search",
                "title": "Search"
              },
              {
                "id": "About",
                "title": "About"
              }
            ],
            "_data_importer": "neo4j",
            "_directed": true,
            "_dom_classes": [],
            "_edges": [
              {
                "color": "#9C27B0",
                "directed": true,
                "end": 2,
                "id": 14,
                "label": "RULED",
                "properties": {
                  "label": "RULED"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#9C27B0",
                "directed": true,
                "end": 3,
                "id": 15,
                "label": "RULED",
                "properties": {
                  "label": "RULED"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#2196F3",
                "directed": true,
                "end": 4,
                "id": 16,
                "label": "BELONGED_TO",
                "properties": {
                  "label": "BELONGED_TO"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 5,
                "id": 17,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 6,
                "id": 18,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 6,
                "id": 19,
                "label": "SPOUSE",
                "properties": {
                  "label": "SPOUSE"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 7,
                "id": 20,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#607D8B",
                "directed": true,
                "end": 8,
                "id": 21,
                "label": "BEQUEATHED_CROWN_TO",
                "properties": {
                  "label": "BEQUEATHED_CROWN_TO"
                },
                "start": 7,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 9,
                "id": 22,
                "label": "IGNORED_CLAIMS_OF",
                "properties": {
                  "label": "IGNORED_CLAIMS_OF"
                },
                "start": 7,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 1,
                "id": 23,
                "label": "IGNORED_CLAIMS_OF",
                "properties": {
                  "label": "IGNORED_CLAIMS_OF"
                },
                "start": 7,
                "thickness_factor": 1
              },
              {
                "color": "#CDDC39",
                "directed": true,
                "end": 1,
                "id": 24,
                "label": "IMPRISONED",
                "properties": {
                  "label": "IMPRISONED"
                },
                "start": 9,
                "thickness_factor": 1
              },
              {
                "color": "#9E9E9E",
                "directed": true,
                "end": 10,
                "id": 25,
                "label": "DEPENDED_ON",
                "properties": {
                  "label": "DEPENDED_ON"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#9C27B0",
                "directed": true,
                "end": 11,
                "id": 26,
                "label": "CREATED_TITLE",
                "properties": {
                  "label": "CREATED_TITLE"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#2196F3",
                "directed": true,
                "end": 12,
                "id": 27,
                "label": "SUCCEEDED_BY",
                "properties": {
                  "label": "SUCCEEDED_BY"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 12,
                "id": 28,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 13,
                "thickness_factor": 1
              },
              {
                "color": "#9E9E9E",
                "directed": true,
                "end": 14,
                "id": 29,
                "label": "DEPENDED_ON",
                "properties": {
                  "label": "DEPENDED_ON"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 17,
                "id": 40,
                "label": "WAR",
                "properties": {
                  "label": "WAR"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 18,
                "id": 41,
                "label": "WAR",
                "properties": {
                  "label": "WAR"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 19,
                "id": 42,
                "label": "WAR",
                "properties": {
                  "label": "WAR"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 3,
                "id": 43,
                "label": "WAR",
                "properties": {
                  "label": "WAR"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 20,
                "id": 44,
                "label": "LEAD",
                "properties": {
                  "label": "LEAD"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 21,
                "id": 45,
                "label": "LEAD",
                "properties": {
                  "label": "LEAD"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 22,
                "id": 46,
                "label": "LEAD",
                "properties": {
                  "label": "LEAD"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 23,
                "id": 47,
                "label": "LEAD",
                "properties": {
                  "label": "LEAD"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#607D8B",
                "directed": true,
                "end": 24,
                "id": 48,
                "label": "DEFEAT",
                "properties": {
                  "label": "DEFEAT"
                },
                "start": 16,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 12,
                "id": 64,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 1,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 7,
                "id": 65,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 29,
                "id": 66,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 1,
                "id": 67,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 30,
                "id": 68,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 31,
                "id": 69,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 32,
                "id": 70,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#673AB7",
                "directed": true,
                "end": 33,
                "id": 71,
                "label": "SUCCESSOR",
                "properties": {
                  "label": "SUCCESSOR"
                },
                "start": 5,
                "thickness_factor": 1
              },
              {
                "color": "#CDDC39",
                "directed": true,
                "end": 34,
                "id": 72,
                "label": "PREFERRED_SUCCESSOR",
                "properties": {
                  "label": "PREFERRED_SUCCESSOR"
                },
                "start": 29,
                "thickness_factor": 1
              },
              {
                "color": "#9E9E9E",
                "directed": true,
                "end": 35,
                "id": 73,
                "label": "FAMILY_RELATION",
                "properties": {
                  "label": "FAMILY_RELATION"
                },
                "start": 34,
                "thickness_factor": 1
              },
              {
                "color": "#9C27B0",
                "directed": true,
                "end": 13,
                "id": 74,
                "label": "MARRIAGE",
                "properties": {
                  "label": "MARRIAGE"
                },
                "start": 35,
                "thickness_factor": 1
              },
              {
                "color": "#2196F3",
                "directed": true,
                "end": 37,
                "id": 91,
                "label": "GRANDPARENT",
                "properties": {
                  "label": "GRANDPARENT"
                },
                "start": 39,
                "thickness_factor": 1
              },
              {
                "color": "#2196F3",
                "directed": true,
                "end": 38,
                "id": 92,
                "label": "GRANDPARENT",
                "properties": {
                  "label": "GRANDPARENT"
                },
                "start": 39,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 40,
                "id": 93,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 34,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 38,
                "id": 94,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 40,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 37,
                "id": 95,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 13,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 16,
                "id": 96,
                "label": "CONTENDER",
                "properties": {
                  "label": "CONTENDER"
                },
                "start": 13,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 8,
                "id": 97,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 41,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 46,
                "id": 98,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 41,
                "thickness_factor": 1
              },
              {
                "color": "#4CAF50",
                "directed": true,
                "end": 47,
                "id": 99,
                "label": "PARENT",
                "properties": {
                  "label": "PARENT"
                },
                "start": 41,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 41,
                "id": 100,
                "label": "SPOUSE",
                "properties": {
                  "label": "SPOUSE"
                },
                "start": 44,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 42,
                "id": 101,
                "label": "SPOUSE",
                "properties": {
                  "label": "SPOUSE"
                },
                "start": 44,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 41,
                "id": 102,
                "label": "SPOUSE",
                "properties": {
                  "label": "SPOUSE"
                },
                "start": 45,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 48,
                "id": 103,
                "label": "SPOUSE",
                "properties": {
                  "label": "SPOUSE"
                },
                "start": 46,
                "thickness_factor": 1
              },
              {
                "color": "#F44336",
                "directed": true,
                "end": 51,
                "id": 117,
                "label": "HELD_TITLE",
                "properties": {
                  "label": "HELD_TITLE"
                },
                "start": 50,
                "thickness_factor": 1
              }
            ],
            "_graph_layout": {},
            "_highlight": [],
            "_license": {},
            "_model_module": "yfiles-jupyter-graphs",
            "_model_module_version": "^1.6.1",
            "_model_name": "GraphModel",
            "_neighborhood": {},
            "_nodes": [
              {
                "color": "#2196F3",
                "id": 1,
                "label": "Elizabeth I",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Elizabeth I",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#4CAF50",
                "id": 2,
                "label": "England",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "England",
                  "label": "Country:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#4CAF50"
              },
              {
                "color": "#4CAF50",
                "id": 3,
                "label": "Ireland",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Ireland",
                  "label": "Country:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#4CAF50"
              },
              {
                "color": "#F44336",
                "id": 4,
                "label": "House Of Tudor",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "House Of Tudor",
                  "label": "__Entity__:Royal family"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#F44336"
              },
              {
                "color": "#2196F3",
                "id": 5,
                "label": "Henry Viii",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Henry Viii",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 6,
                "label": "Anne Boleyn",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Anne Boleyn",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 7,
                "label": "Edward Vi",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Edward Vi",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 8,
                "label": "Lady Jane Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Lady Jane Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 9,
                "label": "Mary",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Mary",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 10,
                "label": "William Cecil",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "William Cecil",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#607D8B",
                "id": 11,
                "label": "Baron Burghley",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Baron Burghley",
                  "label": "Title:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#607D8B"
              },
              {
                "color": "#2196F3",
                "id": 12,
                "label": "James Vi Of Scotland",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "James Vi Of Scotland",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 13,
                "label": "Mary, Queen Of Scots",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Mary, Queen Of Scots",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 14,
                "label": "Francis Walsingham",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Francis Walsingham",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 16,
                "label": "Elizabeth",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Elizabeth",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#4CAF50",
                "id": 17,
                "label": "Spain",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Spain",
                  "label": "Country:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#4CAF50"
              },
              {
                "color": "#4CAF50",
                "id": 18,
                "label": "Netherlands",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Netherlands",
                  "label": "Country:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#4CAF50"
              },
              {
                "color": "#4CAF50",
                "id": 19,
                "label": "France",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "France",
                  "label": "Country:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#4CAF50"
              },
              {
                "color": "#673AB7",
                "id": 20,
                "label": "William Shakespeare",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "William Shakespeare",
                  "label": "Playwright:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#673AB7"
              },
              {
                "color": "#673AB7",
                "id": 21,
                "label": "Christopher Marlowe",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Christopher Marlowe",
                  "label": "Playwright:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#673AB7"
              },
              {
                "color": "#CDDC39",
                "id": 22,
                "label": "Francis Drake",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Francis Drake",
                  "label": "Explorer:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#CDDC39"
              },
              {
                "color": "#CDDC39",
                "id": 23,
                "label": "Walter Raleigh",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Walter Raleigh",
                  "label": "Explorer:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#CDDC39"
              },
              {
                "color": "#9E9E9E",
                "id": 24,
                "label": "Spanish Armada",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Spanish Armada",
                  "label": "Event:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#9E9E9E"
              },
              {
                "color": "#2196F3",
                "id": 29,
                "label": "Mary I",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Mary I",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 30,
                "label": "Jane Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Jane Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 31,
                "label": "Katherine Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Katherine Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 32,
                "label": "Mary Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Mary Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 33,
                "label": "Margaret Clifford",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Margaret Clifford",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 34,
                "label": "Margaret Douglas",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Margaret Douglas",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 35,
                "label": "Henry Stuart, Lord Darnley",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Henry Stuart, Lord Darnley",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 39,
                "label": "Margaret Tudor",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Margaret Tudor",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 37,
                "label": "James Vi",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "James Vi",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 38,
                "label": "Arbella Stuart",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Arbella Stuart",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 40,
                "label": "Charles Stuart",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Charles Stuart",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 41,
                "label": "Frances Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Frances Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 46,
                "label": "Lady Catherine Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Lady Catherine Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 47,
                "label": "Lady Mary Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Lady Mary Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 44,
                "label": "Charles Brandon",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Charles Brandon",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 42,
                "label": "Eleanor Clifford",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Eleanor Clifford",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 45,
                "label": "Henry Grey",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Henry Grey",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 48,
                "label": "Henry Herbert",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Henry Herbert",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#2196F3",
                "id": 50,
                "label": "Elizabeth Petrovna",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Elizabeth Petrovna",
                  "label": "Person:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#2196F3"
              },
              {
                "color": "#607D8B",
                "id": 51,
                "label": "Empress Of Russia",
                "position": [
                  0,
                  0
                ],
                "properties": {
                  "id": "Empress Of Russia",
                  "label": "Title:__Entity__"
                },
                "scale_factor": 1,
                "size": [
                  55,
                  55
                ],
                "styles": {},
                "type": "#607D8B"
              }
            ],
            "_overview": {
              "enabled": null,
              "overview_set": false
            },
            "_selected_graph": [
              [],
              []
            ],
            "_sidebar": {
              "enabled": true,
              "start_with": ""
            },
            "_view_count": null,
            "_view_module": "yfiles-jupyter-graphs",
            "_view_module_version": "^1.6.1",
            "_view_name": "GraphView",
            "layout": "IPY_MODEL_9bac7003afd84cecb4e67a81a396ec8d"
          }
        },
        "9bac7003afd84cecb4e67a81a396ec8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "800px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
